{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd097a40",
   "metadata": {},
   "source": [
    "### Article Generation using N-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd8420",
   "metadata": {},
   "source": [
    "You have to write the urdu article using ngrams (1 grams to 5 grams). So, in short your output must be of 5 paragraphs, the first one is generated using unigram, second one is generated using bigram and so on.\n",
    "\n",
    "Input: Your input is the seed sentence. E.g. first 3 to 4 words of the paragraph.\n",
    "\n",
    "Output: Your output is the consist of 5 paragraphs for each n gram, each of 200 words.\n",
    "\n",
    "You have to make N-gram model using the provided dataset. Dataset can be downloaded from  https://www.kaggle.com/datasets/saurabhshahane/urdu-news-dataset \n",
    "\n",
    "You have to use all News Text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb709115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79601988",
   "metadata": {},
   "source": [
    "### Classify language out of the list given below using just stop words. Remove punctuations, make it lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa286b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Umair\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'basque',\n",
       " 'bengali',\n",
       " 'catalan',\n",
       " 'chinese',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hebrew',\n",
       " 'hinglish',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bdad25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test=\"An article is qualunque member van un class of dedicated words naquele est√£o used with noun phrases per mark the identifiability of the referents of the noun phrases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "266654b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arabic': 0,\n",
       " 'azerbaijani': 1,\n",
       " 'basque': 0,\n",
       " 'bengali': 0,\n",
       " 'catalan': 3,\n",
       " 'chinese': 0,\n",
       " 'danish': 0,\n",
       " 'dutch': 3,\n",
       " 'english': 5,\n",
       " 'finnish': 0,\n",
       " 'french': 1,\n",
       " 'german': 1,\n",
       " 'greek': 0,\n",
       " 'hebrew': 0,\n",
       " 'hinglish': 8,\n",
       " 'hungarian': 1,\n",
       " 'indonesian': 1,\n",
       " 'italian': 2,\n",
       " 'kazakh': 0,\n",
       " 'nepali': 0,\n",
       " 'norwegian': 0,\n",
       " 'portuguese': 1,\n",
       " 'romanian': 1,\n",
       " 'russian': 0,\n",
       " 'slovene': 0,\n",
       " 'spanish': 1,\n",
       " 'swedish': 0,\n",
       " 'tajik': 0,\n",
       " 'turkish': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your output looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f2698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43708fa5",
   "metadata": {},
   "source": [
    "### Rule Based Roman Urdu Text Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f761e",
   "metadata": {},
   "source": [
    "Roman Urdu lacks standard lexicon and usually many spelling variations exist for a given word, e.g., the word zindagi (life) is also written as zindagee, zindagy, zaindagee and zndagi. So, in this question you have to Normalize Roman Urdu words using the following Rules given in the attached Pdf. Your Code works for a complete Sentence or multiple sentences.\n",
    "\n",
    "For Example: zaroori, zaruri, zarori map to the 'zrory'. So zrory becomes the correct word for all representations mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142c871a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
